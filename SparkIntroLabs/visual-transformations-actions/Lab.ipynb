{"cells":[{"cell_type":"markdown","source":["#![Spark Logo](http://sameerf-dbc-labs.s3-website-us-west-2.amazonaws.com/ta_Spark-logo-small.png)\n## A Visual Guide to Spark's API\n### Time to complete: 30 minutes\n#### This lab will introduce you to using Apache Spark 1.4 with the Python API. We will explore common transformations and actions including\n* Actions: Collect, Count, GetNumPartitions, Reduce, Aggregate, Max, Min, Sum, Mean, Variance, Stdev, CountByKey, SaveAsTextFile, \n* Transformations + MISC operations: Map, Filter, FlatMap, GroupBy, GroupByKey, MapPartitions, MapPartitionsWithIndex, Sample, Union, Join, Distinct, Coalese, KeyBy, PartitionBy, Zip\n\n\nNote that these images were inspired by Jeff Thomson's 67 \"PySpark images\"."],"metadata":{}},{"cell_type":"markdown","source":["###Collect\n\nAction / To Driver: Return all items in the RDD to the driver in a single list\n\nStart with this action, since it is used in all of the examples.\n\n![](http://i.imgur.com/DUO6ygB.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3], 2)\ny = x.collect()\nprint(x.glom().collect()) # glom() flattens elements on the same partition\nprint(y)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Transformations\n\nCreate a new RDD from one or more RDDs"],"metadata":{}},{"cell_type":"markdown","source":["###Map\n\nTransformation / Narrow: Return a new RDD by applying a function to each element of this RDD\n\n![](http://i.imgur.com/PxNJf0U.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([\"b\", \"a\", \"c\"])\ny = x.map(lambda z: (z, 1))\nprint(x.collect())\nprint(y.collect())\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["####**Try it!** change the indicated line to produce squares of the original numbers"],"metadata":{}},{"cell_type":"code","source":["#Lab exercise:\n\nx = sc.parallelize([1,2,3,4])\ny = x.map(lambda n: n) #CHANGE the lambda to take a number and returns its square\nprint(x.collect())\nprint(y.collect())"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["#### Filter\n\nTransformation / Narrow: Return a new RDD containing only the elements that satisfy a predicate\n\n![](http://i.imgur.com/GFyji4U.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3])\ny = x.filter(lambda x: x%2 == 1) #keep odd values \nprint(x.collect())\nprint(y.collect())"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["####**Try it!** Change the sample to keep even numbers"],"metadata":{}},{"cell_type":"code","source":["#Lab exercise:\nx = sc.parallelize([1,2,3])\ny = x.filter(  ) #add a lambda parameter to keep only even numbers\nprint(x.collect())\nprint(y.collect())"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["### FlatMap\n\nTransformation / Narrow: Return a new RDD by first applying a function to all elements of this RDD, and then flattening the results\n\n![](http://i.imgur.com/TsSUex8.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3])\ny = x.flatMap(lambda x: (x, x*100, 42))\nprint(x.collect())\nprint(y.collect())\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["### GroupBy\n\nTransformation / Wide: Group the data in the original RDD. Create pairs where the key is the output of a user function, and the value is all items for which the function yields this key.\n\n![](http://i.imgur.com/gdj0Ey8.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize(['John', 'Fred', 'Anna', 'James'])\ny = x.groupBy(lambda w: w[0])\nprint [(k, list(v)) for (k, v) in y.collect()]\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["### GroupByKey\n\nTransformation / Wide: Group the values for each key in the original RDD. Create a new pair where the original key corresponds to this collected group of values.\n\n![](http://i.imgur.com/TlWRGr2.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([('B',5),('B',4),('A',3),('A',2),('A',1)])\ny = x.groupByKey()\nprint(x.collect())\nprint(list((j[0], list(j[1])) for j in y.collect()))\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["### MapPartitions\n\nTransformation / Narrow: Return a new RDD by applying a function to each partition of this RDD\n\n![](http://i.imgur.com/dw8QOLX.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3], 2)\n\ndef f(iterator): yield sum(iterator); yield 42\n\ny = x.mapPartitions(f)\n\nprint(x.glom().collect())\nprint(y.glom().collect())\n"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["### MapPartitionsWithIndex\n\nTransformation / Narrow: Return a new RDD by applying a function to each partition of this RDD, while tracking the index of the original partition\n\n![](http://i.imgur.com/3cGvAF7.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3], 2)\n\ndef f(partitionIndex, iterator): yield (partitionIndex, sum(iterator))\n\ny = x.mapPartitionsWithIndex(f)\n\nprint(x.glom().collect())\nprint(y.glom().collect())\n"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["### Sample\n\nTransformation / Narrow: Return a new RDD containing a statistical sample of the original RDD\n\n![](http://i.imgur.com/LJ56nQq.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1, 2, 3, 4, 5])\ny = x.sample(False, 0.4, 42)\nprint(x.collect())\nprint(y.collect())\n"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["### Union\n\nTransformation / Narrow: Return a new RDD containing all items from two original RDDs. Duplicates are not culled.\n\n![](http://i.imgur.com/XFpbqZ8.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3], 2)\ny = sc.parallelize([3,4], 1)\nz = x.union(y)\nprint(z.glom().collect())\n"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["### Join\n\nTransformation / Wide: Return a new RDD containing all pairs of elements having the same key in the original RDDs\n\n![](http://i.imgur.com/YXL42Nl.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([(\"a\", 1), (\"b\", 2)])\ny = sc.parallelize([(\"a\", 3), (\"a\", 4), (\"b\", 5)])\nz = x.join(y)\nprint(z.collect())\n"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["####**Try it!** Join the RDDs so that each company's name and stock price are collected into a tuple value, whose key is the company ticker symbol."],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([(\"TWTR\", \"Twitter\"), (\"GOOG\", \"Google\"), (\"AAPL\", \"Apple\")])\ny = sc.parallelize([(\"TWTR\", 36), (\"GOOG\", 532), (\"AAPL\", 127)])\n\n#Add code here to perform a join and print the result"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["### Distinct\n\nTransformation / Wide: Return a new RDD containing distinct items from the original RDD (omitting all duplicates)\n\n![](http://i.imgur.com/Vqgy2a4.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3,3,4])\ny = x.distinct()\n\nprint(y.collect())\n"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["### Coalesce\n\nTransformation / Narrow or Wide: Return a new RDD which is reduced to a smaller number of partitions\n\n![](http://i.imgur.com/woQiM7E.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1, 2, 3, 4, 5], 3)\ny = x.coalesce(2)\nprint(x.glom().collect())\nprint(y.glom().collect())\n"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["### KeyBy\n\nTransformation / Narrow: Create a Pair RDD, forming one pair for each item in the original RDD. The pair?s key is calculated from the value via a user-supplied function.\n\n![](http://i.imgur.com/nqYhDW5.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize(['John', 'Fred', 'Anna', 'James'])\ny = x.keyBy(lambda w: w[0])\nprint y.collect()"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":["####**Try it!** Create an RDD from this list, and then use .keyBy to create a pair RDD where the state abbreviation is the key and the city + state is the value (e.g., (\"NY\", \"New York, NY\")) ... For extra credit, add a .map that strips out the redundant state abbreviation to yield pairs like (\"NY\", \"New York\")."],"metadata":{}},{"cell_type":"code","source":["data = [\"New York, NY\", \"Philadelphia, PA\", \"Denver, CO\", \"San Francisco, CA\"]\n# Add code to parallelize the list to an RDD\n# call .keyBy on the RDD to create an RDD of pairs\n\n"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["### PartitionBy\n\nTransformation / Wide: Return a new RDD with the specified number of partitions, placing original items into the partition returned by a user supplied function\n\n![](http://i.imgur.com/QHDWwYv.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([('J','James'),('F','Fred'), ('A','Anna'),('J','John')], 3)\n\ny = x.partitionBy(2, lambda w: 0 if w[0] < 'H' else 1)\n\nprint x.glom().collect()\nprint y.glom().collect()"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["### Zip\n\nTransformation / Narrow: Return a new RDD containing pairs whose key is the item in the original RDD, and whose value is that item?s corresponding element (same partition, same index) in a second RDD\n\n![](http://i.imgur.com/5J0lg6g.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1, 2, 3])\ny = x.map(lambda n:n*n)\nz = x.zip(y)\n\nprint(z.collect())"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["## Actions\n\nCalculate a result (e.g., numeric data or creata a non-RDD data structure), or produce a side effect, such as writing output to disk"],"metadata":{}},{"cell_type":"markdown","source":["### GetNumPartitions\n\nAction / To Driver: Return the number of partitions in RDD\n\n![](http://i.imgur.com/9yhDsVX.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3], 2)\ny = x.getNumPartitions()\n\nprint(x.glom().collect())\nprint(y)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["### Reduce\n\nAction / To Driver: Aggregate all the elements of the RDD by applying a user function pairwise to elements and partial results, and return a result to the driver\n\n![](http://i.imgur.com/R72uzwX.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3,4])\ny = x.reduce(lambda a,b: a+b)\n\nprint(x.collect())\nprint(y)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["### Aggregate\n\nAction / To Driver: Aggregate all the elements of the RDD by: \n  - applying a user function to combine elements with user-supplied objects, \n  - then combining those user-defined results via a second user function, \n  - and finally returning a result to the driver.\n  \n![](http://i.imgur.com/7MLnYeh.png)"],"metadata":{}},{"cell_type":"code","source":["seqOp = lambda data, item: (data[0] + [item], data[1] + item)\ncombOp = lambda d1, d2: (d1[0] + d2[0], d1[1] + d2[1])\n\nx = sc.parallelize([1,2,3,4])\n\ny = x.aggregate(([], 0), seqOp, combOp)\n\nprint(y)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["####**Try it!** Can you use .aggregate to collect the inputs into a plain list -- so that the output of your .aggregate is just like that of .collect? How about producing a plain total, just like .sum? What does that tell you about the amount of data returned from .aggregate?"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([1,2,3,4])\n\n#define appropriate seqOp and combOp\nseqOp = lambda #...\ncombOp = lambda #... \n\ny = x.aggregate(  ) #add correct parameters\n\n# these two lines should produce the same thing\nprint(x.collect())\nprint(y)\n"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["### Max, Min, Sum, Mean, Variance, Stdev\n\nAction / To Driver: Compute the respective function (maximum value, minimum value, sum, mean, variance, or standard deviation) from a numeric RDD\n\n![](http://i.imgur.com/HUCtib1.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([2,4,1])\nprint(x.collect())\nprint(x.max(), x.min(), x.sum(), x.mean(), x.variance(), x.stdev())"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":["### CountByKey\n\nAction / To Driver: Return a map of keys and counts of their occurrences in the RDD\n\n![](http://i.imgur.com/jvQTGv6.png)"],"metadata":{}},{"cell_type":"code","source":["x = sc.parallelize([('J', 'James'), ('F','Fred'), \n                    ('A','Anna'), ('J','John')])\n\ny = x.countByKey()\nprint(y)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":["### SaveAsTextFile\n\nAction / Distributed: Save the RDD to the filesystem indicated in the path\n\n![](http://i.imgur.com/Tb2Q9mG.png)"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.rm(\"/temp/demo\", True)\nx = sc.parallelize([2,4,1])\nx.saveAsTextFile(\"/temp/demo\")\n\ny = sc.textFile(\"/temp/demo\")\nprint(y.collect())\n"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":58}],"metadata":{"name":"Lab","notebookId":17443},"nbformat":4,"nbformat_minor":0}
